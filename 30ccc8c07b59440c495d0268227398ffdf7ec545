{
  "comments": [
    {
      "key": {
        "uuid": "939caa1b_eb1b4d58",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 22,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2020-05-20T14:13:38Z",
      "side": 1,
      "message": "Why not create a dedicated thread pool, use it for scheduling the pending tasks and then shut it down? This would avoid the need for\n\"protecting\" the defaultQueue from overload and simplify the coding as we wouldn\u0027t need a ChainedExecutor in this case.",
      "revId": "30ccc8c07b59440c495d0268227398ffdf7ec545",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "adb8f6e1_9793e954",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 22,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-05-20T14:53:00Z",
      "side": 1,
      "message": "As mentioned in another comment on this change, there is another change that proposes using its own threadpool, The downside to creating another threadpool is that all threadpools get similar priorities and thus every new thread pool robs the existing threadpools of some processing and memory. I think that the addition of new threadpools for lower priority work is the wrong direction, and we probably have done too much of it already. Other examples of background plugin tasks that I know of that I would like to use this pattern for are the cleaners in the websessions-flatfile and batch pluigns, as these don\u0027t deserve their own thread pools either. I think new threadpools make sense for tasks that should not have their priority lowered, i.e. it is good for tasks that need to be protected from lower priority work, but theradpools are not a good solution for tasks that are lower priority work that we are trying to protect higher priority tasks from. We mostly put tasks in the defaultQueue when we think the tasks should are low enough priority that they should not run otherplaces! I think this chained approach is a less resource intensive approach to lower priority \"background\" tasks and hope that we might see something like it for more lower priority tasks eventually. That being said, I do think we need a solution to this scheduling problem, and if the other change is favored over this one I will not be upset, we can always improve upon it later.\n\nAs for future improvements, ideally this scheduling work would get allocated to the remote threadpool which each event is for. This could be potentially be done with more complicated architectural changes, I\u0027m not sure that is worth it as the immediate fix, but I do think it is worth considering soon. For example, it might not be too hard to split the reading of events apart from the scheduling of tasks, and that would have two benefits. If one task reads all the events from disk, and puts them into a Set for each remote, they would get properly de-duped right away (that fact that this de-duping doesn\u0027t currently happen is another bug in the existing codebase), and the reading would likely be fast since it hopefully would not trigger the same \"project cache loading\" slowness as scheduling. Then, the scheduling, which likely would trigger the project cache slowness could be done for each Set on each remotes threadpool, thus appropriately distributing this work where it belongs. Additionally if this scheduling were then done using a \"ChainedScehduler\" like this one on the threadpool for each remote, it would have the additional benefit of lowering the priority of the scheduling of these pending tasks below the priority of the user generated replication tasks.",
      "parentUuid": "939caa1b_eb1b4d58",
      "revId": "30ccc8c07b59440c495d0268227398ffdf7ec545",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b79f26fd_5cadc98d",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 22,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2020-05-20T15:29:03Z",
      "side": 1,
      "message": "\u003e As mentioned in another comment on this change, there is another change that proposes using its own threadpool, The downside to creating another threadpool is that all threadpools get similar priorities and thus every new thread pool robs the existing threadpools of some processing and memory. I think that the addition of new threadpools for lower priority work is the wrong direction, and we probably have done too much of it already. Other examples of background plugin tasks that I know of that I would like to use this pattern for are the cleaners in the websessions-flatfile and batch pluigns, as these don\u0027t deserve their own thread pools either.\n\nThis is likely because there was no concept of a low-prio queue in Gerrit core which plugins could use.\n\n\u003e I think new threadpools make sense for tasks that should not have their priority lowered, i.e. it is good for tasks that need to be protected from lower priority work, but theradpools are not a good solution for tasks that are lower priority work that we are trying to protect higher priority tasks from. We mostly put tasks in the defaultQueue when we think the tasks should are low enough priority that they should not run otherplaces!\n\nWhat guarantees that the tasks put in default queue will execute with lower\nprio? The size of the default queue is configurable [1] and if an admin\nconfigures a higher number of threads, then the tasks in the default queue\nwill also rob other thread pools of CPU and memory.\n\n[1] https://gerrit-review.googlesource.com/Documentation/config-gerrit.html#execution\n\n\u003e I think this chained approach is a less resource intensive approach to lower priority \"background\" tasks and hope that we might see something like it for more lower priority tasks eventually. That being said, I do think we need a solution to this scheduling problem, and if the other change is favored over this one I will not be upset, we can always improve upon it later.\n\nI agree. The main reason I commented on this change was that it felt wrong to\nme that a generic concept like ChainedScheduler gets implemented in a plugin.\nIf we need a concept like that then it belongs to Gerrit core so that other\nplugins can also make use of it.\n\nHowever, if you would prefer to first start with the ChainedScheduler in the\nreplication plugin with the intention of moving it to Gerrit core, or providing\nan alternative low-prio queue in the Gerrit core then I am also fine with this\nchange.",
      "parentUuid": "adb8f6e1_9793e954",
      "revId": "30ccc8c07b59440c495d0268227398ffdf7ec545",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3a0f3582_e1edce4f",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 22,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-05-20T16:04:42Z",
      "side": 1,
      "message": "\u003e This is likely because there was no concept of a low-prio queue in Gerrit core which plugins could use.\n\nI think the defaultQueue basically serves that purpose.\n\n\u003e What guarantees that the tasks put in default queue will execute with lower\n\u003e prio? The size of the default queue is configurable [1] and if an admin\n\u003e configures a higher number of threads, then the tasks in the default queue\n\u003e will also rob other thread pools of CPU and memory.\n\u003e \n\u003e [1] https://gerrit-review.googlesource.com/Documentation/config-gerrit.html#execution\n\nI agree. It would be good if an admin only ever had to bump this when there is enough background (low priority) load work on their server that they need more threads to keep up. In that case, it is appropriate to then rob the higher priority tasks of their resources in order to throttle them to a point that the background work can keep up. Ideally this adjustment would not be needed, and the queue size would auto-adjust to ensure that it keeps up with the work being generated. \n\nThis adjustment is probably good at tweaking throughput, but an admin might also be used because of latency issues, i.e. when one lo priority task runs too long and blocks other low priority tasks increasing their latency. However it would be better to never have to adjust this for latency issues, as such issues would be more effectively deal with by splitting them up, like what the ChainedScheduler does. If it makes it to core, we can start doing this.\n\n\u003e I agree. The main reason I commented on this change was that it felt wrong to\n\u003e me that a generic concept like ChainedScheduler gets implemented in a plugin.\n\u003e If we need a concept like that then it belongs to Gerrit core so that other\n\u003e plugins can also make use of it.\n\nGlad to see the idea has support and yes that would be nice to get it in core!\n\n\u003e However, if you would prefer to first start with the ChainedScheduler in the\n\u003e replication plugin with the intention of moving it to Gerrit core, or providing\n\u003e an alternative low-prio queue in the Gerrit core then I am also fine with this\n\u003e change.\n\nI think it might make sense to bring it in early to the plugin since it is not required to be in core, and then to bring it in core when there is a core user of it? It also probably makes sense to not block plugins fixes from using the ChainedScheduler on it being merged in core.",
      "parentUuid": "b79f26fd_5cadc98d",
      "revId": "30ccc8c07b59440c495d0268227398ffdf7ec545",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "df5ffaf8_2e8cdd04",
        "filename": "/COMMIT_MSG",
        "patchSetId": 2
      },
      "lineNbr": 22,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-05-21T23:44:17Z",
      "side": 1,
      "message": "\u003e As for future improvements, ideally this scheduling work would get allocated to the remote threadpool which each event is for...\n\nA sample of what this might look like is here: https://gerrit-review.googlesource.com/c/plugins/replication/+/268612\n\nThat change is much more complicated, and is probably better kept for a newer release. I made it here so that it can be compared to this current change. As far as startup is concerned, this current change is faster than 268612 because it does not wait for the tasks to be read from disk, and this could be very significant on a slow NFS, or a slow disk. So I think we should choose the current change to ensure that startup is faster, and then if we want, we can additionally rebase 268612 on this change to get the fairness benefit of scheduling via the appropriate threadpool. As a fruther future improvement, it would still be good to split the on-disk storage per Destination so that even the reading is done on the appropriate threadpools, but that requires another ondisk format change.",
      "parentUuid": "3a0f3582_e1edce4f",
      "revId": "30ccc8c07b59440c495d0268227398ffdf7ec545",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": false
    }
  ]
}