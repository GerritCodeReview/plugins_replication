{
  "comments": [
    {
      "key": {
        "uuid": "d19be536_1dd69a48",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 11,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-11T22:29:14Z",
      "side": 1,
      "message": "Once Change-Id: I224c2ce is merged, the statement may not be true anymore.",
      "range": {
        "startLine": 10,
        "startChar": 26,
        "endLine": 11,
        "endChar": 27
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d3249d2e_5fdfbbd9",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 11,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-08-11T22:47:24Z",
      "side": 1,
      "message": "\u003e Once Change-Id: I224c2ce is merged, the statement may not be true anymore.\n\nI will try to  update this commit message if this no longer is the case.",
      "parentUuid": "d19be536_1dd69a48",
      "range": {
        "startLine": 10,
        "startChar": 26,
        "endLine": 11,
        "endChar": 27
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "adca82d5_41859ec7",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-11T22:29:14Z",
      "side": 1,
      "message": "When there is no load, they will still be serialised. Where is the mechanism that makes them faster in absence of load?",
      "range": {
        "startLine": 24,
        "startChar": 27,
        "endLine": 24,
        "endChar": 39
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3d962158_a5bb6943",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-11T22:29:14Z",
      "side": 1,
      "message": "I did not find any throttling mechanism in the ChainedScheduler: could you provide a source file + line number of where that is implemented? What I see from the code is a serial firing of the events using a stream.",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "eef6cc70_f7157a9d",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-08-11T22:47:24Z",
      "side": 1,
      "message": "\u003e I did not find any throttling mechanism in the ChainedScheduler: could you provide a source file + line number of where that is implemented? What I see from the code is a serial firing of the events using a stream.\n\nLine 104 here:\nhttps://gerrit-review.googlesource.com/c/plugins/replication/+/267812/12/src/main/java/com/googlesource/gerrit/plugins/replication/ChainedScheduler.java\nThe next event is scheduled before executing the current event. Since an event\u0027s Task must be running before it can schedule another one, only one event can ever be scheduled concurrently. However nothing prevents multiple event Tasks from running at the same time, and the next one is scheduled before executing the current event. If there are free threads then it is possible for more than one event to be executing at the same time. This is what I mean by \"natural\", no special code is required to throttle this way, the \"scheduleNext then execute\" ordering takes care of the throttling.",
      "parentUuid": "3d962158_a5bb6943",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4102add1_3875b4b9",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-08-11T22:47:24Z",
      "side": 1,
      "message": "\u003e When there is no load, they will still be serialised. Where is the mechanism that makes them faster in absence of load?\n\nThe sentence on lines 22-23 explains how this throttling (and parallelism) is achieved.",
      "parentUuid": "adca82d5_41859ec7",
      "range": {
        "startLine": 24,
        "startChar": 27,
        "endLine": 24,
        "endChar": 39
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d5559254_17a36117",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-12T08:00:03Z",
      "side": 1,
      "message": "\u003e \u003e When there is no load, they will still be serialised. Where is the mechanism that makes them faster in absence of load?\n\u003e \n\u003e The sentence on lines 22-23 explains how this throttling (and parallelism) is achieved.\n\nThanks, I\u0027ll follow up in the previous comment then.",
      "parentUuid": "4102add1_3875b4b9",
      "range": {
        "startLine": 24,
        "startChar": 27,
        "endLine": 24,
        "endChar": 39
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f99da00f_357c5619",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-12T08:00:03Z",
      "side": 1,
      "message": "\u003e \u003e I did not find any throttling mechanism in the ChainedScheduler: could you provide a source file + line number of where that is implemented? What I see from the code is a serial firing of the events using a stream.\n\u003e \n\u003e Line 104 here:\n\u003e https://gerrit-review.googlesource.com/c/plugins/replication/+/267812/12/src/main/java/com/googlesource/gerrit/plugins/replication/ChainedScheduler.java\n\u003e The next event is scheduled before executing the current event. Since an event\u0027s Task must be running before it can schedule another one, only one event can ever be scheduled concurrently.\n\nYes, that is what I understood from the code.\n\n\u003e However nothing prevents multiple event Tasks from running at the same time, and the next one is scheduled before executing the current event. If there are free threads then it is possible for more than one event to be executing at the same time.\n\nAh, gotcha. Because just before start running one you schedule the next one. And where do you throttle? How do you make sure that you\u0027re not occupying the full capacity of the execution pool? How do you give priority to the interactive events?\n\n\u003e This is what I mean by \"natural\", no special code is required to throttle this way, the \"scheduleNext then execute\" ordering takes care of the throttling.\n\nGotcha, but unless we are limiting the thread utilisation in \"some way\", I\u0027m not sure we can say we are throttling.",
      "parentUuid": "eef6cc70_f7157a9d",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "7e6d4627_32d92112",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-12T08:20:54Z",
      "side": 1,
      "message": "\u003e \u003e \u003e I did not find any throttling mechanism in the ChainedScheduler: could you provide a source file + line number of where that is implemented? What I see from the code is a serial firing of the events using a stream.\n\u003e \u003e \n\u003e \u003e Line 104 here:\n\u003e \u003e https://gerrit-review.googlesource.com/c/plugins/replication/+/267812/12/src/main/java/com/googlesource/gerrit/plugins/replication/ChainedScheduler.java\n\u003e \u003e The next event is scheduled before executing the current event. Since an event\u0027s Task must be running before it can schedule another one, only one event can ever be scheduled concurrently.\n\u003e \n\u003e Yes, that is what I understood from the code.\n\u003e \n\u003e \u003e However nothing prevents multiple event Tasks from running at the same time, and the next one is scheduled before executing the current event. If there are free threads then it is possible for more than one event to be executing at the same time.\n\u003e \n\u003e Ah, gotcha. Because just before start running one you schedule the next one. And where do you throttle? How do you make sure that you\u0027re not occupying the full capacity of the execution pool? How do you give priority to the interactive events?\n\nLet clarify with an example of \"throttling\", so that it becomes clearer what I was expecting to see in the code based on the commit message.\n\nIf the queue is completely empty, then execute all the replayed events as fast as you can. If there are interactive events coming through, then check that the replayed events are taking no more than X% (configurable?) of the running threads. If one replayed event, coming to a running state, goes over the X% limit, then throttle.\n\nP.S. The above is an example of throttling. Of course you can achieve that in many ways.\n\nAnother alternative solution would be, instead of throttling, just introduce the concept of \"priority queue\", exactly like the one in the airports for the security checks. The \"executor\" is shared (the number of slots for putting your stuff on the conveyor) but you could come from the general queue or from the \"priority queue\". If there is someone in the priority queue waiting, the general queue gets locked to a minimum of executors (let\u0027s say only 1 slot out of 4). If the priority queue is empty, the general queue gets the full capacity.\n\nThanks again for your patience in explaining the code.\n\n\u003e \u003e This is what I mean by \"natural\", no special code is required to throttle this way, the \"scheduleNext then execute\" ordering takes care of the throttling.\n\u003e \n\u003e Gotcha, but unless we are limiting the thread utilisation in \"some way\", I\u0027m not sure we can say we are throttling.",
      "parentUuid": "f99da00f_357c5619",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "13e51e5d_9f01f57b",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2020-08-12T12:16:34Z",
      "side": 1,
      "message": "I also believe that I understand the ChainedScheduler, let me add a few\ncomments to the Lucas observations.\n\n\n\u003e \u003e Ah, gotcha. Because just before start running one you schedule the next one. \n\nCorrect.\n\n\u003e And where do you throttle? How do you make sure that you\u0027re not occupying the full capacity of the execution pool? How do you give priority to the interactive events?\n\nBy having at most one (pending) task in the queue at any time. As you correctly\nobserved, one task needs to be picked up from the queue (by a free thread)\nand only then the next one can go into the queue.\n\n\n\u003e Another alternative solution would be, instead of throttling, just introduce the concept of \"priority queue\", exactly like the one in the airports for the security checks. The \"executor\" is shared (the number of slots for putting your stuff on the conveyor) but you could come from the general queue or from the \"priority queue\". If there is someone in the priority queue waiting, the general queue gets locked to a minimum of executors (let\u0027s say only 1 slot out of 4). If the priority queue is empty, the general queue gets the full capacity.\n\nThis is an interesting question. \n\nLet me also try to translate the ChainedScheduler\ninto an airport based example: There is only one queue where all the passengers\nwho are *allowed* to enter the queue have the same priority.\nHowever, the passengers are classified into two groups: priority and low-prio.\nA priority passenger can enter the queue at any time.\nA low-prio passenger can only enter the queue at the moment when an already\nqueued low-prio passenger gets called to be processed.\n\nThis way, at any time, there is at most one low-prio passenger in the queue.\nIf there are no priority-passengers then the low-prio will get processed faster as\nall counters will serve them. But as soon as a priority passenger arrives\nhe will be the next or the second next, having to wait for at most one\nlow-prio passenger which is already queued.\n\n\n\u003e \n\u003e Thanks again for your patience in explaining the code.\n\u003e \n\u003e \u003e \u003e This is what I mean by \"natural\", no special code is required to throttle this way, the \"scheduleNext then execute\" ordering takes care of the throttling.\n\u003e \u003e \n\u003e \u003e Gotcha, but unless we are limiting the thread utilisation in \"some way\", I\u0027m not sure we can say we are throttling.",
      "parentUuid": "7e6d4627_32d92112",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "14c6cb27_5f7bb046",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2020-08-12T14:23:35Z",
      "side": 1,
      "message": "Now that we have a solid understanding of the ChainedScheduler and based on\nthe analogies with the airport queues, it seems to me that an Executor\nbased on a priority queue would achieve the same effect. Martin, what do\nyou think?",
      "parentUuid": "13e51e5d_9f01f57b",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "8fae6871_058f9198",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-12T14:48:02Z",
      "side": 1,
      "message": "\u003e I also believe that I understand the ChainedScheduler, let me add a few\n\u003e comments to the Lucas observations.\n\u003e \n\u003e \n\u003e \u003e \u003e Ah, gotcha. Because just before start running one you schedule the next one. \n\u003e \n\u003e Correct.\n\u003e \n\u003e \u003e And where do you throttle? How do you make sure that you\u0027re not occupying the full capacity of the execution pool? How do you give priority to the interactive events?\n\u003e \n\u003e By having at most one (pending) task in the queue at any time. As you correctly\n\u003e observed, one task needs to be picked up from the queue (by a free thread)\n\u003e and only then the next one can go into the queue.\n\nHowever, during startup, Gerrit isn\u0027t active yet, it is just starting the plugins and the HTTP and SSH acceptors are not finalised.\n\nBecause the current implementation is putting another task in the queue *before* execution the fire of the replication event, they could end up occupying all replication threads at once.\n\nShould we also define an \"intial delay\" so that we don\u0027t start replaying immediately but we give time for any interactive replication event to come through?\n\n\u003e \u003e Another alternative solution would be, instead of throttling, just introduce the concept of \"priority queue\", exactly like the one in the airports for the security checks. The \"executor\" is shared (the number of slots for putting your stuff on the conveyor) but you could come from the general queue or from the \"priority queue\". If there is someone in the priority queue waiting, the general queue gets locked to a minimum of executors (let\u0027s say only 1 slot out of 4). If the priority queue is empty, the general queue gets the full capacity.\n\u003e \n\u003e This is an interesting question. \n\u003e \n\u003e Let me also try to translate the ChainedScheduler\n\u003e into an airport based example: There is only one queue where all the passengers\n\u003e who are *allowed* to enter the queue have the same priority.\n\u003e However, the passengers are classified into two groups: priority and low-prio.\n\u003e A priority passenger can enter the queue at any time.\n\u003e A low-prio passenger can only enter the queue at the moment when an already\n\u003e queued low-prio passenger gets called to be processed.\n\u003e \n\u003e This way, at any time, there is at most one low-prio passenger in the queue.\n\u003e If there are no priority-passengers then the low-prio will get processed faster as\n\u003e all counters will serve them. But as soon as a priority passenger arrives\n\u003e he will be the next or the second next, having to wait for at most one\n\u003e low-prio passenger which is already queued.\n\nThanks for the explanation, now it makes sense.\nBasically, the \"external stream of the replication events\" *IS* the low-prio passengers queue.\n\nIt would be nice to have this mechanism in the Gerrit\u0027s queue system, so that:\na. The low-prio queue backlog is visible in the gerrit show-queue command\nb. the high-prio/low-prio queueing system can be used in other parts of gerrit\n\nWith this solution, I could not see effectively how many events are waiting to be served in the low-prio queue, as the \u0027show-queue\u0027 would give me only always only 1 element for the replayed events.\n\n\u003e \u003e \n\u003e \u003e Thanks again for your patience in explaining the code.\n\u003e \u003e \n\u003e \u003e \u003e \u003e This is what I mean by \"natural\", no special code is required to throttle this way, the \"scheduleNext then execute\" ordering takes care of the throttling.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Gotcha, but unless we are limiting the thread utilisation in \"some way\", I\u0027m not sure we can say we are throttling.",
      "parentUuid": "13e51e5d_9f01f57b",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f3bed1d0_aef68dec",
        "filename": "/COMMIT_MSG",
        "patchSetId": 12
      },
      "lineNbr": 24,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-08-12T14:51:48Z",
      "side": 1,
      "message": "\u003e Now that we have a solid understanding of the ChainedScheduler and based on\n\u003e the analogies with the airport queues, it seems to me that an Executor\n\u003e based on a priority queue would achieve the same effect. Martin, what do\n\u003e you think?\n\nI don\u0027t understand how one could apply a priority queue (the data structure) to this code. A PR requires some property on items in the PR that is comparable to determine the order that things come out of the queue. The order things come out of a PR is only related to that property and not to insertion order. That seems very different from what would ne desired here. What would be the objective to use a PQ?\n\nThis change implements exactly the behavior that I think is most appropriate here in a very simple way. It allows an open throttle on items when utilization is low, and it throttles things down to one item at a time (no parallelism) when utilization is high.",
      "parentUuid": "14c6cb27_5f7bb046",
      "range": {
        "startLine": 23,
        "startChar": 56,
        "endLine": 24,
        "endChar": 17
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9ab2a70c_6efd55ea",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 12
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-11T22:29:14Z",
      "side": 1,
      "message": "I believe I start to understand more how the ChainedScheduler works. However, as it is done in a separate class for making it reusable, I would love to see some API contract validation.\n\nI am also struggling to find in the code the behaviour described in the commit message.",
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "5c790dac_90978cc0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 12
      },
      "lineNbr": 0,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2020-08-11T22:47:24Z",
      "side": 1,
      "message": "\u003e I believe I start to understand more how the ChainedScheduler works. However, as it is done in a separate class for making it reusable, I would love to see some API contract validation.\n\nWhat do you have in mind, ChainedScheduler unit tests?\n \n\u003e I am also struggling to find in the code the behaviour described in the commit message.\n\nIs this a repeat of your comment on the commit message?",
      "parentUuid": "9ab2a70c_6efd55ea",
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9bd00cd4_b0eaac38",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 12
      },
      "lineNbr": 0,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-12T14:48:02Z",
      "side": 1,
      "message": "Thanks Sa≈°a for your feedback.",
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "e447db75_17763441",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ChainedScheduler.java",
        "patchSetId": 12
      },
      "lineNbr": 107,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2020-08-12T08:00:03Z",
      "side": 1,
      "message": "This exception is effectively swallowed: not traced, just ignored.\nWhilst I understand the reason (thanks for the comment), it should be at least traced so that it would become easier to identify potential problems.",
      "range": {
        "startLine": 107,
        "startChar": 15,
        "endLine": 107,
        "endChar": 33
      },
      "revId": "75430697bdcfa2daa1b41c57b673d13d9e797ed4",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    }
  ]
}