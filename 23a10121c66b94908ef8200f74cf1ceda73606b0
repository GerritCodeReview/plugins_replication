{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "dd8ede1d_7c59cf56",
        "filename": "/COMMIT_MSG",
        "patchSetId": 8
      },
      "lineNbr": 11,
      "author": {
        "id": 1002666
      },
      "writtenOn": "2022-05-12T18:43:28Z",
      "side": 1,
      "message": "How long is the recoverAll method actually taking to run? How many running tasks are in storage?",
      "range": {
        "startLine": 11,
        "startChar": 24,
        "endLine": 11,
        "endChar": 50
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d90a4033_ad8c6edc",
        "filename": "/COMMIT_MSG",
        "patchSetId": 8
      },
      "lineNbr": 11,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2022-05-13T07:58:00Z",
      "side": 1,
      "message": "\u003e How long is the recoverAll method actually taking to run? How many running tasks are in storage?\n\nAbout 30K tasks. Recovering tasks synchronously keeps Gerrit start blocked.",
      "parentUuid": "dd8ede1d_7c59cf56",
      "range": {
        "startLine": 11,
        "startChar": 24,
        "endLine": 11,
        "endChar": 50
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "07d25bbd_3c1fa2e9",
        "filename": "/COMMIT_MSG",
        "patchSetId": 8
      },
      "lineNbr": 11,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2022-05-13T17:55:36Z",
      "side": 1,
      "message": "\u003e \u003e How long is the recoverAll method actually taking to run? How many running tasks are in storage?\n\u003e \n\u003e About 30K tasks. \n\nIn theory that would mean that you had 30K replication tasks running when the server shutdown, is that correct? It seems that can only happen if you have at least 30K replication threads configured, which seems enormous?\n\n\u003e Recovering tasks synchronously keeps Gerrit start blocked.\n\nTo do this asynchronously and safely not delay the server startup, then I think you would need to put all of the replication startup code which follows this also in the background, and ensure that it runs serially after the recoverAll(), and ensure that no replication tasks start before the recoverAll() completes.",
      "parentUuid": "d90a4033_ad8c6edc",
      "range": {
        "startLine": 11,
        "startChar": 24,
        "endLine": 11,
        "endChar": 50
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "6a40d6c5_64097c38",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 8
      },
      "lineNbr": 0,
      "author": {
        "id": 1065256
      },
      "writtenOn": "2022-05-17T07:36:49Z",
      "side": 1,
      "message": "I found that the issue is actually a different one. We recently started to use a downported version of my change introducing the refs-updated plugin (Ic0534d03dee6759ba4cb6b19ae87fd75269b437b). This change also changes the format of the stored tasks:\n\nBefore:\n  {\n    \"project\": \"All-Users\",\n    \"ref\": \"refs/users/85/1029885\",\n    \"uri\": \"example.com:/gerrit/git/All-Users.git\",\n    \"remote\": \"example.com\"\n  }\n\nAfter:\n  {\n    \"project\": \"All-Users\",\n    \"refs\": [\n        \"refs/users/85/1029885\"\n    ],\n    \"uri\": \"example.com:/gerrit/git/All-Users.git\",\n    \"remote\": \"example.com\"\n  }\n\nThe tasks in our case were still in the old format. It seems that GSON endlessly tries to parse the file and thus the start is stuck. I will open a bug immediately and work on a fix.",
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "13d153e0_211994ee",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1002666
      },
      "writtenOn": "2022-05-12T18:43:28Z",
      "side": 1,
      "message": "This method expects all tasks to already have been recovered from storage by the time of its first scheduled run (because it tries to fire/start any task found in \u0027waiting\u0027). Making the storage recovery async will break that expectation.",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "db85bc49_f5d6bb91",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2022-05-13T17:55:36Z",
      "side": 1,
      "message": "Also, replicationTasksStorage.recoveAll() will move stored running tasks to waiting, so it can cause tasks that get started to be put back in waiting, which can cause them to run again if the synchronizePendingEvents(Prune.FALSE) is still running distributor is running (which will call synchronizePendingEvents(Prune.TRUE)).",
      "parentUuid": "13d153e0_211994ee",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "14f46a1d_f30bf43c",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2022-05-16T08:23:18Z",
      "side": 1,
      "message": "What if we move all the steps (from line 102 until 105, look at the base version) to\nthe background?\nAny other ides/proposals on how to avoid blocking Gerrit startup from here?",
      "parentUuid": "db85bc49_f5d6bb91",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c5fc5afd_6794cce7",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2022-05-16T22:40:24Z",
      "side": 1,
      "message": "While I think it wouldn\u0027t hurt the plugin to do so, I am not sure that it si a good solution for your problem. It seems like it will mostly shift your problem to the replication plugin startup then. Would it make more sense to try and make the plugin scale better? If you indeed have 30K threads configured to do replication, would it make sense to try and take advantage of those threads somehow to do the recovery faster? This way you not only make Gerrit startup faster, but you make replication available faster?",
      "parentUuid": "14f46a1d_f30bf43c",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "90b8fe2c_16093a4b",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2022-05-17T07:21:55Z",
      "side": 1,
      "message": "\u003e If you indeed have 30K threads configured to do replication...\n\nWe do not need/have 30K threads to do replication. What I wrote was that we had 30K replication tasks waiting to be (re)scheduled (this was caused by an outage of a replica for a longer time).",
      "parentUuid": "c5fc5afd_6794cce7",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9e4bdcfe_34d8bb13",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1065256
      },
      "writtenOn": "2022-05-17T07:36:49Z",
      "side": 1,
      "message": "A note on the number of 30k tasks. This happened on one of our test servers. This server was recently updated from Gerrit 3.2 to 3.4 and had replication configured for a remote that was offline. Thus, after the upgrade the replication plugin started replication for all refs that were updated as part of the schema migration. Since the remote was offline, replication failed for all of them and were stuck in a retry loop.\nWe don\u0027t have 30k threads configured.\n\nYes, this was caused by a system that was not running as it was supposed to, but it highlighted the issue due to the unusual large number of tasks.\n\nI agree that it would make sense to use all the threads that were configured for a replication to a given remote would improve the situation.",
      "parentUuid": "c5fc5afd_6794cce7",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "85250402_e802fdda",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 106,
      "author": {
        "id": 1003873
      },
      "writtenOn": "2022-05-17T09:17:47Z",
      "side": 1,
      "message": "The root cause of the Gerrit server never finishing the start was actually an infinite loop in the replication plugin which is now fixed by this change:\nhttps://gerrit-review.googlesource.com/c/plugins/replication/+/337304/1\n\nSo, the 30K waiting tasks could slow down a bit the server start but this wasn\u0027t the main issue.",
      "parentUuid": "9e4bdcfe_34d8bb13",
      "range": {
        "startLine": 106,
        "startChar": 6,
        "endLine": 106,
        "endChar": 30
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9bde563b_ebb3bbd4",
        "filename": "src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java",
        "patchSetId": 8
      },
      "lineNbr": 108,
      "author": {
        "id": 1002666
      },
      "writtenOn": "2022-05-12T18:43:28Z",
      "side": 1,
      "message": "This object expects all tasks to already have been recovered from storage and fired/started by the time of its first scheduled run (because it then calls synchronizePendingEvents(Prune.TRUE)). Making the storage recovery async will break that expectation.",
      "range": {
        "startLine": 108,
        "startChar": 6,
        "endLine": 108,
        "endChar": 17
      },
      "revId": "23a10121c66b94908ef8200f74cf1ceda73606b0",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153"
    }
  ]
}